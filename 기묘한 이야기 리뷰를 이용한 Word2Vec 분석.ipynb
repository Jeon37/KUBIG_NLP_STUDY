{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2A6pGNyBQvH1"
   },
   "source": [
    "**왓챠피디아(https://peida.watcha.com/ko-KR) 리뷰 분석**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**과제 옵션**\n",
    "1. 제공된 데이터셋/본인이 직접 선택한 데이터셋을 통해 간단한 CBOW/skip-gram 모델 훈련해보기  \n",
    "2. t-sne를 활용해 직접 훈련한 word2vec 모델에 다양한 단어를 입력해 시각화해보기  \n",
    "3. 직접 훈련한 word2vec 모델에 관심있는 단어를 입력하고 해당 단어와 유사한 단어들 살펴보기  \n",
    "4. 특정 두 단어 사이의 유사도(거리)를 측정해보고 모델이 잘 훈련되었는지 판단해보기  \n",
    "5. word2vec 모델 훈련 시 window_size 등 다양한 초모수 설정 변경해가며 결과 비교해보기  \n",
    "6. gensim 패키지에서 제공하는 사전학습 모델을 활용해 각자 창의적으로 해보고 싶은 것 해보기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eat5YxycQtbs"
   },
   "source": [
    "### 1. 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "tFrOGygRQtbs",
    "outputId": "39ee82ea-2b8a-44fc-c9f8-c2d1e31bf3a3"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>코멘트</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>아이들에 대한 묘사가 너무 절묘하다. 유난히 똑똑한 아이들임을 보여주면서도 순진함 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>스토리, 음악, 캐릭터까지 '슈퍼 에이트'보다 더 7080스럽고 사랑스럽지만 동시에...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>왜 아무도 바브에게 관심을 쏟지 않는 거죠...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>재밌을랑말랑하는 기묘함</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>취향은 아니지만 보는것을 멈출수가없었네요..</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 코멘트\n",
       "0  아이들에 대한 묘사가 너무 절묘하다. 유난히 똑똑한 아이들임을 보여주면서도 순진함 ...\n",
       "1  스토리, 음악, 캐릭터까지 '슈퍼 에이트'보다 더 7080스럽고 사랑스럽지만 동시에...\n",
       "2                         왜 아무도 바브에게 관심을 쏟지 않는 거죠...\n",
       "3                                       재밌을랑말랑하는 기묘함\n",
       "4                           취향은 아니지만 보는것을 멈출수가없었네요.."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "from konlpy.tag import Okt\n",
    "\n",
    "movie_review = pd.read_csv(\"./왓챠피디아 기묘한 이야기 시즌1~4 코멘트.csv\",index_col = 0)\n",
    "movie_review[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "# 결측값 존재 유무 확인\n",
    "print(movie_review.isnull().values.any())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "922\n"
     ]
    }
   ],
   "source": [
    "# 리뷰 개수 출력\n",
    "print(len(movie_review))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {
    "id": "UJSFPREQQtb4"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>코멘트</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>아이들에 대한 묘사가 너무 절묘하다 유난히 똑똑한 아이들임을 보여주면서도 순진함 속...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>스토리 음악 캐릭터까지 슈퍼 에이트보다 더 스럽고 사랑스럽지만 동시에 중독성 강한 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>왜 아무도 바브에게 관심을 쏟지 않는 거죠</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>재밌을랑말랑하는 기묘함</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>취향은 아니지만 보는것을 멈출수가없었네요</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 코멘트\n",
       "0  아이들에 대한 묘사가 너무 절묘하다 유난히 똑똑한 아이들임을 보여주면서도 순진함 속...\n",
       "1  스토리 음악 캐릭터까지 슈퍼 에이트보다 더 스럽고 사랑스럽지만 동시에 중독성 강한 ...\n",
       "2                            왜 아무도 바브에게 관심을 쏟지 않는 거죠\n",
       "3                                       재밌을랑말랑하는 기묘함\n",
       "4                             취향은 아니지만 보는것을 멈출수가없었네요"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 정규 표현식 이용, 한글 외 문자 제거\n",
    "movie_review['코멘트'] = movie_review['코멘트'].str.replace(\"[^ ㄱ-ㅎㅏ-ㅣ가-힣]\",\"\")\n",
    "movie_review[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 띄어쓰기 교정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "from pykospacing.kospacing import Spacing\n",
    "spacing = Spacing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_sent = []\n",
    "for sent in movie_review['코멘트']:\n",
    "    new_sent.append(spacing(sent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_corpus = new_sent\n",
    "movie_review['코멘트_space'] = new_corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 네이버 한글 맞춤법 검사기 : 띄어쓰기 포함되어 있음!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hanspell import spell_checker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>코멘트</th>\n",
       "      <th>코멘트_space</th>\n",
       "      <th>코멘트_spell_checker</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>아이들에 대한 묘사가 너무 절묘하다 유난히 똑똑한 아이들임을 보여주면서도 순진함 속...</td>\n",
       "      <td>아이들에 대한 묘사가 너무 절묘하다 유난히 똑똑한 아이들임을 보여주면서도 순진함 속...</td>\n",
       "      <td>아이들에 대한 묘사가 너무 절묘하다 유난히 똑똑한 아이들임을 보여주면서도 순진함 속...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>스토리 음악 캐릭터까지 슈퍼 에이트보다 더 스럽고 사랑스럽지만 동시에 중독성 강한 ...</td>\n",
       "      <td>스토리 음악 캐릭터까지 슈퍼 에이트보다 더 스럽고 사랑스럽지만 동시에 중독성 강한 ...</td>\n",
       "      <td>스토리 음악 캐릭터까지 슈퍼 에이트보다 더스럽고 사랑스럽지만 동시에 중독성 강한 호...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>왜 아무도 바브에게 관심을 쏟지 않는 거죠</td>\n",
       "      <td>왜 아무도 바브에게 관심을 쏟지 않는 거죠</td>\n",
       "      <td>왜 아무도 바브에게 관심을 쏟지 않는 거죠</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>재밌을랑말랑하는 기묘함</td>\n",
       "      <td>재밌을 랑 말랑하는 기 묘함</td>\n",
       "      <td>재밌을랑 말랑하는 기묘함</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>취향은 아니지만 보는것을 멈출수가없었네요</td>\n",
       "      <td>취향은 아니지만 보는 것을 멈출 수가 없었네요</td>\n",
       "      <td>취향은 아니지만 보는 것을 멈출 수가 없었네요</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>917</th>\n",
       "      <td>ㄹㄹㄹ</td>\n",
       "      <td>ㄹㄹㄹ</td>\n",
       "      <td>ㄹㄹㄹ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>918</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>919</th>\n",
       "      <td>기묘한가 재미있는가 의문을 가지고 보지만 답은 역시 명성대로</td>\n",
       "      <td>기묘한 가 재미있는 가 의문을 가지고 보지만 답은 역시 명성대로</td>\n",
       "      <td>기묘한가 재미있는가 의문을 가지고 보지만 답은 역시 명성대로</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>920</th>\n",
       "      <td>미쳐</td>\n",
       "      <td>미쳐</td>\n",
       "      <td>미쳐</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>921</th>\n",
       "      <td>대머리 호퍼</td>\n",
       "      <td>대머리 호퍼</td>\n",
       "      <td>대머리 호퍼</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>922 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   코멘트  \\\n",
       "0    아이들에 대한 묘사가 너무 절묘하다 유난히 똑똑한 아이들임을 보여주면서도 순진함 속...   \n",
       "1    스토리 음악 캐릭터까지 슈퍼 에이트보다 더 스럽고 사랑스럽지만 동시에 중독성 강한 ...   \n",
       "2                              왜 아무도 바브에게 관심을 쏟지 않는 거죠   \n",
       "3                                         재밌을랑말랑하는 기묘함   \n",
       "4                               취향은 아니지만 보는것을 멈출수가없었네요   \n",
       "..                                                 ...   \n",
       "917                                                ㄹㄹㄹ   \n",
       "918                                                      \n",
       "919                  기묘한가 재미있는가 의문을 가지고 보지만 답은 역시 명성대로   \n",
       "920                                                 미쳐   \n",
       "921                                             대머리 호퍼   \n",
       "\n",
       "                                             코멘트_space  \\\n",
       "0    아이들에 대한 묘사가 너무 절묘하다 유난히 똑똑한 아이들임을 보여주면서도 순진함 속...   \n",
       "1    스토리 음악 캐릭터까지 슈퍼 에이트보다 더 스럽고 사랑스럽지만 동시에 중독성 강한 ...   \n",
       "2                              왜 아무도 바브에게 관심을 쏟지 않는 거죠   \n",
       "3                                      재밌을 랑 말랑하는 기 묘함   \n",
       "4                            취향은 아니지만 보는 것을 멈출 수가 없었네요   \n",
       "..                                                 ...   \n",
       "917                                                ㄹㄹㄹ   \n",
       "918                                                      \n",
       "919                기묘한 가 재미있는 가 의문을 가지고 보지만 답은 역시 명성대로   \n",
       "920                                                 미쳐   \n",
       "921                                             대머리 호퍼   \n",
       "\n",
       "                                     코멘트_spell_checker  \n",
       "0    아이들에 대한 묘사가 너무 절묘하다 유난히 똑똑한 아이들임을 보여주면서도 순진함 속...  \n",
       "1    스토리 음악 캐릭터까지 슈퍼 에이트보다 더스럽고 사랑스럽지만 동시에 중독성 강한 호...  \n",
       "2                              왜 아무도 바브에게 관심을 쏟지 않는 거죠  \n",
       "3                                        재밌을랑 말랑하는 기묘함  \n",
       "4                            취향은 아니지만 보는 것을 멈출 수가 없었네요  \n",
       "..                                                 ...  \n",
       "917                                                ㄹㄹㄹ  \n",
       "918                                                     \n",
       "919                  기묘한가 재미있는가 의문을 가지고 보지만 답은 역시 명성대로  \n",
       "920                                                 미쳐  \n",
       "921                                             대머리 호퍼  \n",
       "\n",
       "[922 rows x 3 columns]"
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spelled_sent = []\n",
    "for sent in movie_review['코멘트']:\n",
    "    spell_sent = spell_checker.check(sent)\n",
    "    checked_sent = spell_sent.checked\n",
    "    spelled_sent.append(checked_sent)\n",
    "        \n",
    "movie_review['코멘트_spell_checker'] = spelled_sent\n",
    "movie_review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "del movie_review['코멘트_space']\n",
    "movie_review.columns = [\"코멘트_orig\",\"코멘트_clean\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 불용어 정의\n",
    "stopwords = ['이','있','하','것','들','그','되','수','보','않','없','나','사람','주','아니','등','같','우리',\n",
    "            '때','년','가','한','지','대하','오','말','일','그렇','위하','때문','그것','두','말하','알','그러나',\n",
    "            '받','모사','그런','똣','문제','더','사회','많','그리고','좋','크','따르','중','나오','가지','씨',\n",
    "            '시키','만들','지금','생각하','그러','속','하나','집','살','모르','적','월','데','자신','안','어떤',\n",
    "            '내','경우','명','생각','시간','그녀','다시','이런','앞','보이','번','나','다른','어떻','여자','개',\n",
    "            '전','들','사실','이렇','점','싶','말','정도','좀','원','잘','통하','소리','높','다','없다','않다',\n",
    "            '의','과','이다','를','있다','도','에','을','와','왜','고','같다','하다','으로','가다','는','보다',\n",
    "            '인','로','너무','에서','되다','게','은','화','거','자다','까지','싶다','못','하고','들다','그렇다',\n",
    "            '정말','만','력','주다','에는']\n",
    "\n",
    "\n",
    "# 형태소 분석기 OKT를 사용한 토큰화 작업\n",
    "okt = Okt()\n",
    "tokenized_data = []\n",
    "for sentence in movie_review['코멘트_clean']:\n",
    "    temp_X = okt.morphs(sentence, stem=True) # 토큰화\n",
    "    temp_X = [word for word in temp_X if not word in stopwords] # 불용어 제거\n",
    "    tokenized_data.append(temp_X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 모델 훈련(CBOW vs. skip-gram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CBOW 방법 사용\n",
    "model1 = Word2Vec(sentences = tokenized_data,\n",
    "                 workers = 4,\n",
    "                 size = 100, \n",
    "                 min_count = 5,\n",
    "                 window = 5, \n",
    "                 sg = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [],
   "source": [
    "# skip-gram 방법 사용\n",
    "model2 = Word2Vec(sentences = tokenized_data,\n",
    "                 workers = 4,\n",
    "                 size = 100, \n",
    "                 min_count = 5,\n",
    "                 window = 5, \n",
    "                 sg = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Parameters**  \n",
    "```workers``` : 실행할 병렬 프로세스의 수, 코어수, 주로 4-6사이 지정\n",
    "\n",
    "```size``` : 각 단어에 대한 임베딩 된 벡터차원 정의, size=2라면 한 문장의 벡터는 [-0.1248574, 0.255778]와 같은 형태를 가지게 된다.\n",
    "\n",
    "```min_count``` : 단어에 대한 최소 빈도수. min_count=5라면 빈도수 5 이하 무시\n",
    "\n",
    "```window``` : 문맥 윈도우 수, 양쪽으로 몇 개의 단어까지 고려해서 의미를 파악할 것인지 지정하는 것\n",
    "\n",
    "```sample``` : 빠른 학습을 위해 정답 단어 라벨에 대한 다운샘플링 비율을 지정하는 것, 보통 0.001이 좋은 성능을 낸다고 한다.\n",
    "\n",
    "```sg``` : 1이면 skip-gram 방법을 사용하고, 0이면 CBOW 방법을 사용한다. → default = 1\n",
    "\n",
    "```iter``` : epoch와 같은 뜻으로 학습 반복 횟수를 지정한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(694, 100)\n",
      "(692, 100)\n"
     ]
    }
   ],
   "source": [
    "# CBOW 완성된 임베딩 매트릭스의 크기 확인\n",
    "print(model.wv.vectors.shape)\n",
    "\n",
    "# skip-gram 모델 완성된 임베딩 매트릭스의 크기 확인\n",
    "print(model2.wv.vectors.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ```wv.most_similar()``` : 가장 유사한 단어들을 추출할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('시즌', 0.9943159818649292),\n",
       " ('드라마', 0.9938040971755981),\n",
       " ('재밌다', 0.9934017658233643),\n",
       " ('연기', 0.9933466911315918),\n",
       " ('아이', 0.9932005405426025),\n",
       " ('연출', 0.9931702613830566),\n",
       " ('캐릭터', 0.9927265048027039),\n",
       " ('많다', 0.9927006959915161),\n",
       " ('일레븐', 0.9925738573074341),\n",
       " ('좋다', 0.9925539493560791)]"
      ]
     },
     "execution_count": 346,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(\"스토리\") # CBOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('흥미진진', 0.9996491074562073),\n",
       " ('미치다', 0.9996362924575806),\n",
       " ('연출', 0.9996293187141418),\n",
       " ('일레븐', 0.9996097087860107),\n",
       " ('귀엽다', 0.9995805621147156),\n",
       " ('많다', 0.9995736479759216),\n",
       " ('볼', 0.9995663166046143),\n",
       " ('버리다', 0.9995652437210083),\n",
       " ('추천', 0.9995623230934143),\n",
       " ('등장인물', 0.999561071395874)]"
      ]
     },
     "execution_count": 369,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.wv.most_similar(\"스토리\") # skip-gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('좋다', 0.9910829663276672),\n",
       " ('드라마', 0.9909542798995972),\n",
       " ('연기', 0.9905955791473389),\n",
       " ('시즌', 0.9904861450195312),\n",
       " ('아이', 0.9904405474662781),\n",
       " ('느낌', 0.9904223680496216),\n",
       " ('나오다', 0.9904062747955322),\n",
       " ('괴물', 0.9896777868270874),\n",
       " ('캐릭터', 0.989277720451355),\n",
       " ('아니다', 0.9891306161880493)]"
      ]
     },
     "execution_count": 342,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(\"호러\") # CBOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('괴물', 0.9995923042297363),\n",
       " ('세계', 0.9995922446250916),\n",
       " ('시절', 0.9995921850204468),\n",
       " ('느낌', 0.9995903968811035),\n",
       " ('미스터리', 0.99958336353302),\n",
       " ('스릴러', 0.9995710253715515),\n",
       " ('느끼다', 0.9995632171630859),\n",
       " ('주인공', 0.9995575547218323),\n",
       " ('살다', 0.9995497465133667),\n",
       " ('굉장하다', 0.999549388885498)]"
      ]
     },
     "execution_count": 383,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.wv.most_similar(\"호러\") #skip-gram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ```wv.similarity()``` : 유비(analogy), 두 단어를 입력해 코사인 유사도 계산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9995711"
      ]
     },
     "execution_count": 395,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.wv.similarity('호러','스릴러')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.99920076"
      ]
     },
     "execution_count": 462,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.wv.similarity('윌','조이스') #부정확"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 초모수 값 변경"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) size 모수 조절 : 50~300\n",
    "- 각 단어에 대한 임베딩 된 벡터차원 정의\n",
    "- 너무 작은 값이 아니라면 학습의 경향이 달라지지 않는다.  \n",
    "- 보통 논문/실험 등에서는 100~300 정도의 값으로 설정  \n",
    "- size가 클수록 더 큰 메모리가 필요하지만 더 정확한 모델을 만들 수 있음  \n",
    "- 적절한 차원 수 계산 = 단어의 개수 ** 0.25  \n",
    "⇒ 출처 : https://stackoverflow.com/questions/48479915/what-is-the-preferred-ratio-between-the-vocabulary-size-and-embedding-dimension"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### size = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('미치다', 0.9997945427894592),\n",
       " ('귀엽다', 0.9997934103012085),\n",
       " ('추천', 0.9997921586036682),\n",
       " ('흥미진진', 0.9997838735580444),\n",
       " ('궁금하다', 0.9997825622558594),\n",
       " ('많다', 0.9997814893722534),\n",
       " ('일레븐', 0.9997813105583191),\n",
       " ('걸', 0.9997766613960266),\n",
       " ('긴장감', 0.9997761249542236),\n",
       " ('등장인물', 0.9997757077217102)]"
      ]
     },
     "execution_count": 477,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3 = Word2Vec(sentences = tokenized_data,\n",
    "                 workers = 4,\n",
    "                 size = 200, \n",
    "                 min_count = 5,\n",
    "                 window = 5, \n",
    "                 sg = 1)\n",
    "\n",
    "model3.wv.most_similar(\"스토리\") # skip-gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('스릴러', 0.9997791051864624),\n",
       " ('미스터리', 0.9997729063034058),\n",
       " ('괴물', 0.9997543692588806),\n",
       " ('판타지', 0.999752938747406),\n",
       " ('연대', 0.9997494220733643),\n",
       " ('살다', 0.9997481107711792),\n",
       " ('영화', 0.9997472763061523),\n",
       " ('세계', 0.9997472763061523),\n",
       " ('느끼다', 0.9997464418411255),\n",
       " ('장르', 0.9997435808181763)]"
      ]
     },
     "execution_count": 478,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3.wv.most_similar(\"호러\") #skip-gram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### size = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('대단하다', 0.9998520016670227),\n",
       " ('긴장감', 0.9998484253883362),\n",
       " ('보여주다', 0.9998483061790466),\n",
       " ('일레븐', 0.9998472929000854),\n",
       " ('걸', 0.9998466372489929),\n",
       " ('시리즈', 0.999846339225769),\n",
       " ('미치다', 0.9998456835746765),\n",
       " ('느끼다', 0.999845027923584),\n",
       " ('배우', 0.9998441934585571),\n",
       " ('모든', 0.9998440146446228)]"
      ]
     },
     "execution_count": 475,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model4 = Word2Vec(sentences = tokenized_data,\n",
    "                 workers = 4,\n",
    "                 size = 300, \n",
    "                 min_count = 5,\n",
    "                 window = 5, \n",
    "                 sg = 1)\n",
    "\n",
    "model4.wv.most_similar(\"스토리\") # skip-gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('스릴러', 0.9998499751091003),\n",
       " ('미스터리', 0.9998387098312378),\n",
       " ('연대', 0.9998334646224976),\n",
       " ('판타지', 0.9998325109481812),\n",
       " ('성장', 0.9998301863670349),\n",
       " ('느끼다', 0.9998301267623901),\n",
       " ('영화', 0.9998282790184021),\n",
       " ('드라마', 0.9998273849487305),\n",
       " ('장르', 0.9998252391815186),\n",
       " ('향수', 0.9998241662979126)]"
      ]
     },
     "execution_count": 476,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model4.wv.most_similar(\"호러\") #skip-gram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### size = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('기다리다', 0.9989835023880005),\n",
       " ('미치다', 0.998934805393219),\n",
       " ('와중', 0.9988172650337219),\n",
       " ('재현', 0.9987524747848511),\n",
       " ('존나', 0.9987190961837769),\n",
       " ('무섭다', 0.9987044334411621),\n",
       " ('시리즈', 0.9986265897750854),\n",
       " ('가득하다', 0.9986243844032288),\n",
       " ('감동', 0.9986122250556946),\n",
       " ('흥미진진', 0.9985907673835754)]"
      ]
     },
     "execution_count": 481,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model5 = Word2Vec(sentences = tokenized_data,\n",
    "                 workers = 4,\n",
    "                 size = 10, \n",
    "                 min_count = 5,\n",
    "                 window = 5, \n",
    "                 sg = 1)\n",
    "\n",
    "model5.wv.most_similar(\"스토리\") # skip-gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('시절', 0.9988580346107483),\n",
       " ('스릴러', 0.9987044334411621),\n",
       " ('킹', 0.9986584186553955),\n",
       " ('긴장', 0.9986554980278015),\n",
       " ('판', 0.9985576868057251),\n",
       " ('크리처', 0.9985381364822388),\n",
       " ('시키다', 0.9984337091445923),\n",
       " ('아쉽다', 0.9983357191085815),\n",
       " ('맛', 0.9983145594596863),\n",
       " ('판타지', 0.9982568621635437)]"
      ]
     },
     "execution_count": 482,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model5.wv.most_similar(\"호러\") #skip-gram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) min_count 모수 조절 : 2~100\n",
    "- 최소 빈도수  \n",
    "- 해당 빈도수보다 작게 등장한 단어는 모델 학습에서 배제  \n",
    "- 값을 작게 할수록 빈도 적은 단어들도 계산에 포함돼 속도가 느려지고 모델의 크기가 커짐  \n",
    "- 일반적으로 10 ~ 100 사이 값 권장"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### min_count = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('미치다', 0.9997718334197998),\n",
       " ('추천', 0.9997693300247192),\n",
       " ('귀엽다', 0.9997686743736267),\n",
       " ('연출', 0.9997653961181641),\n",
       " ('대단하다', 0.9997615814208984),\n",
       " ('궁금하다', 0.9997596144676208),\n",
       " ('일레븐', 0.9997562170028687),\n",
       " ('긴장감', 0.9997526407241821),\n",
       " ('흥미진진', 0.9997520446777344),\n",
       " ('배우', 0.9997481107711792)]"
      ]
     },
     "execution_count": 488,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2_1 = Word2Vec(sentences = tokenized_data,\n",
    "                 workers = 4,\n",
    "                 size = 200, \n",
    "                 min_count = 10,\n",
    "                 window = 5, \n",
    "                 sg = 1)\n",
    "\n",
    "model2_1.wv.most_similar(\"스토리\") # skip-gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('스릴러', 0.9997598528862),\n",
       " ('미스터리', 0.9997431039810181),\n",
       " ('괴물', 0.999737024307251),\n",
       " ('느끼다', 0.999732494354248),\n",
       " ('나오다', 0.999730110168457),\n",
       " ('판타지', 0.9997291564941406),\n",
       " ('연기', 0.9997258186340332),\n",
       " ('장르', 0.9997247457504272),\n",
       " ('세계', 0.9997239708900452),\n",
       " ('오다', 0.9997239708900452)]"
      ]
     },
     "execution_count": 489,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2_1.wv.most_similar(\"호러\") # skip-gram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### min_count = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('재밌다', 0.20830407738685608),\n",
       " ('기묘하다', 0.20131590962409973),\n",
       " ('시즌', 0.18763238191604614),\n",
       " ('드라마', 0.18192651867866516),\n",
       " ('애', 0.18060463666915894),\n",
       " ('나오다', 0.14819592237472534),\n",
       " ('연대', 0.12232963740825653),\n",
       " ('이야기', 0.0951845794916153),\n",
       " ('캐릭터', 0.07883840799331665),\n",
       " ('느낌', 0.06769584119319916)]"
      ]
     },
     "execution_count": 494,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2_2 = Word2Vec(sentences = tokenized_data,\n",
    "                 workers = 4,\n",
    "                 size = 200, \n",
    "                 min_count = 50,\n",
    "                 window = 5, \n",
    "                 sg = 1)\n",
    "\n",
    "model2_2.wv.most_similar(\"스토리\") # skip-gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"word '호러' not in vocabulary\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-495-91693a0865be>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel2_2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmost_similar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"호러\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# skip-gram\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\gensim\\models\\keyedvectors.py\u001b[0m in \u001b[0;36mmost_similar\u001b[1;34m(self, positive, negative, topn, restrict_vocab, indexer)\u001b[0m\n\u001b[0;32m    551\u001b[0m                 \u001b[0mmean\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweight\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mword\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    552\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 553\u001b[1;33m                 \u001b[0mmean\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweight\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mword_vec\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muse_norm\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    554\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mword\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    555\u001b[0m                     \u001b[0mall_words\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\gensim\\models\\keyedvectors.py\u001b[0m in \u001b[0;36mword_vec\u001b[1;34m(self, word, use_norm)\u001b[0m\n\u001b[0;32m    466\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    467\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 468\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"word '%s' not in vocabulary\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mword\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    469\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    470\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget_vector\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mword\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: \"word '호러' not in vocabulary\""
     ]
    }
   ],
   "source": [
    "model2_2.wv.most_similar(\"호러\") # skip-gram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) window 모수 조절 : 2~10\n",
    "- 타깃 단어를 예측하기 위해 사용할 앞뒤 맥락 단어의 개수  \n",
    "- 값이 커지면 단어의 학습량이 증가 → 계산량 증가, 단어의 의미적 정확도 증가  \n",
    "- 값이 클수록 주요 도메인 정보를 더 많이 잡아낼 수 있음  \n",
    "- 값이 작을수록 단어 하나하나 자체에 대해 더 많이 잡아낼 수 있음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### window = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Word2Vec' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-5e730899b86e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m model3_1 = Word2Vec(sentences = tokenized_data,\n\u001b[0m\u001b[0;32m      2\u001b[0m                  \u001b[0mworkers\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m                  \u001b[0msize\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m200\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m                  \u001b[0mmin_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m                  \u001b[0mwindow\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Word2Vec' is not defined"
     ]
    }
   ],
   "source": [
    "model3_1 = Word2Vec(sentences = tokenized_data,\n",
    "                 workers = 4,\n",
    "                 size = 200, \n",
    "                 min_count = 5,\n",
    "                 window = 1, \n",
    "                 sg = 1)\n",
    "\n",
    "model3_1.wv.most_similar(\"스토리\") # skip-gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model3_1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-79f365b694b9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel3_1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmost_similar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"호러\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# skip-gram\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'model3_1' is not defined"
     ]
    }
   ],
   "source": [
    "model3_1.wv.most_similar(\"호러\") # skip-gram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### window = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('드라마', 0.9998314380645752),\n",
       " ('재밌다', 0.9998151063919067),\n",
       " ('캐릭터', 0.9998118877410889),\n",
       " ('시즌', 0.9998093843460083),\n",
       " ('많다', 0.9998037219047546),\n",
       " ('귀엽다', 0.9998030662536621),\n",
       " ('괴물', 0.9998029470443726),\n",
       " ('연출', 0.9997992515563965),\n",
       " ('연기', 0.9997958540916443),\n",
       " ('일레븐', 0.9997954368591309)]"
      ]
     },
     "execution_count": 498,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3_2 = Word2Vec(sentences = tokenized_data,\n",
    "                 workers = 4,\n",
    "                 size = 200, \n",
    "                 min_count = 5,\n",
    "                 window = 3, \n",
    "                 sg = 1)\n",
    "\n",
    "model3_2.wv.most_similar(\"스토리\") # skip-gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 499,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('나오다', 0.9997599720954895),\n",
       " ('드라마', 0.9997506141662598),\n",
       " ('캐릭터', 0.9997338652610779),\n",
       " ('연기', 0.9997336864471436),\n",
       " ('괴물', 0.9997214078903198),\n",
       " ('이야기', 0.9997164011001587),\n",
       " ('스토리', 0.9997121691703796),\n",
       " ('느끼다', 0.9997121095657349),\n",
       " ('영화', 0.9997093081474304),\n",
       " ('연대', 0.9997087717056274)]"
      ]
     },
     "execution_count": 499,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3_2.wv.most_similar(\"호러\") # skip-gram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### window = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('긴장감', 0.999727189540863),\n",
       " ('뛰어나다', 0.9997236728668213),\n",
       " ('선사', 0.9997175931930542),\n",
       " ('연출', 0.9997164607048035),\n",
       " ('등등', 0.9997159242630005),\n",
       " ('액션', 0.9997130632400513),\n",
       " ('대다', 0.9997124671936035),\n",
       " ('너무나', 0.9997103214263916),\n",
       " ('훌륭하다', 0.999708890914917),\n",
       " ('밖에', 0.9997082948684692)]"
      ]
     },
     "execution_count": 500,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3_3 = Word2Vec(sentences = tokenized_data,\n",
    "                 workers = 4,\n",
    "                 size = 200, \n",
    "                 min_count = 5,\n",
    "                 window = 10, \n",
    "                 sg = 1)\n",
    "\n",
    "model3_3.wv.most_similar(\"스토리\") # skip-gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 502,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('스릴러', 0.9997023344039917),\n",
       " ('미스터리', 0.9997010827064514),\n",
       " ('장르', 0.9996613264083862),\n",
       " ('가지다', 0.999659538269043),\n",
       " ('연대', 0.9996564388275146),\n",
       " ('섞다', 0.9996458292007446),\n",
       " ('판타지', 0.9996434450149536),\n",
       " ('온갖', 0.9996329545974731),\n",
       " ('스러운', 0.9996294975280762),\n",
       " ('크리처', 0.9996261596679688)]"
      ]
     },
     "execution_count": 502,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3_3.wv.most_similar(\"호러\") # skip-gram"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "KUBIG_2021_Summer_NLP_Study_2주차_과제_전지우.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
